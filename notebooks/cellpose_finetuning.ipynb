{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49c6d19d",
   "metadata": {},
   "source": [
    "# ðŸ¦’ Fine-tuning Cellpose with BioEngine âš™ï¸â˜ï¸"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467fa03e",
   "metadata": {},
   "source": [
    "## Installation and module imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23c3efd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hypha-rpc in /data/nmechtel/mambaforge/envs/bioengine-worker/lib/python3.11/site-packages (0.20.53)\n",
      "Requirement already satisfied: kaibu-utils in /data/nmechtel/mambaforge/envs/bioengine-worker/lib/python3.11/site-packages (0.1.14)\n",
      "Requirement already satisfied: matplotlib in /data/nmechtel/mambaforge/envs/bioengine-worker/lib/python3.11/site-packages (3.10.3)\n",
      "Requirement already satisfied: numpy in /data/nmechtel/mambaforge/envs/bioengine-worker/lib/python3.11/site-packages (from hypha-rpc) (1.26.4)\n",
      "Requirement already satisfied: msgpack>=1.0.2 in /data/nmechtel/mambaforge/envs/bioengine-worker/lib/python3.11/site-packages (from hypha-rpc) (1.1.0)\n",
      "Requirement already satisfied: shortuuid>=1.0.8 in /data/nmechtel/mambaforge/envs/bioengine-worker/lib/python3.11/site-packages (from hypha-rpc) (1.0.13)\n",
      "Requirement already satisfied: websockets<=13.1 in /data/nmechtel/mambaforge/envs/bioengine-worker/lib/python3.11/site-packages (from hypha-rpc) (13.1)\n",
      "Requirement already satisfied: munch in /data/nmechtel/mambaforge/envs/bioengine-worker/lib/python3.11/site-packages (from hypha-rpc) (4.0.0)\n",
      "Requirement already satisfied: Pillow in /data/nmechtel/mambaforge/envs/bioengine-worker/lib/python3.11/site-packages (from kaibu-utils) (11.2.1)\n",
      "Requirement already satisfied: geojson in /data/nmechtel/mambaforge/envs/bioengine-worker/lib/python3.11/site-packages (from kaibu-utils) (3.2.0)\n",
      "Requirement already satisfied: scikit-image in /data/nmechtel/mambaforge/envs/bioengine-worker/lib/python3.11/site-packages (from kaibu-utils) (0.25.2)\n",
      "Requirement already satisfied: requests in /data/nmechtel/mambaforge/envs/bioengine-worker/lib/python3.11/site-packages (from kaibu-utils) (2.32.3)\n",
      "Requirement already satisfied: pyodide-http in /data/nmechtel/mambaforge/envs/bioengine-worker/lib/python3.11/site-packages (from kaibu-utils) (0.2.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /data/nmechtel/mambaforge/envs/bioengine-worker/lib/python3.11/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /data/nmechtel/mambaforge/envs/bioengine-worker/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /data/nmechtel/mambaforge/envs/bioengine-worker/lib/python3.11/site-packages (from matplotlib) (4.58.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /data/nmechtel/mambaforge/envs/bioengine-worker/lib/python3.11/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /data/nmechtel/mambaforge/envs/bioengine-worker/lib/python3.11/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /data/nmechtel/mambaforge/envs/bioengine-worker/lib/python3.11/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /data/nmechtel/mambaforge/envs/bioengine-worker/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /data/nmechtel/mambaforge/envs/bioengine-worker/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /data/nmechtel/mambaforge/envs/bioengine-worker/lib/python3.11/site-packages (from requests->kaibu-utils) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /data/nmechtel/mambaforge/envs/bioengine-worker/lib/python3.11/site-packages (from requests->kaibu-utils) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /data/nmechtel/mambaforge/envs/bioengine-worker/lib/python3.11/site-packages (from requests->kaibu-utils) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /data/nmechtel/mambaforge/envs/bioengine-worker/lib/python3.11/site-packages (from requests->kaibu-utils) (2025.4.26)\n",
      "Requirement already satisfied: scipy>=1.11.4 in /data/nmechtel/mambaforge/envs/bioengine-worker/lib/python3.11/site-packages (from scikit-image->kaibu-utils) (1.15.2)\n",
      "Requirement already satisfied: networkx>=3.0 in /data/nmechtel/mambaforge/envs/bioengine-worker/lib/python3.11/site-packages (from scikit-image->kaibu-utils) (3.4.2)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /data/nmechtel/mambaforge/envs/bioengine-worker/lib/python3.11/site-packages (from scikit-image->kaibu-utils) (2.37.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /data/nmechtel/mambaforge/envs/bioengine-worker/lib/python3.11/site-packages (from scikit-image->kaibu-utils) (2025.5.10)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /data/nmechtel/mambaforge/envs/bioengine-worker/lib/python3.11/site-packages (from scikit-image->kaibu-utils) (0.4)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # For pyodide in the browser\n",
    "    import micropip\n",
    "\n",
    "    await micropip.install([\"pyodide-http\", \"hypha-rpc\", \"httpx\"])\n",
    "\n",
    "    # 2. Patch requests\n",
    "    import pyodide_http\n",
    "\n",
    "    pyodide_http.patch_all()  # Patch all libraries\n",
    "except ImportError:\n",
    "    # For native python with pip\n",
    "    import subprocess\n",
    "\n",
    "    subprocess.call([\"pip\", \"install\", \"hypha-rpc\", \"kaibu-utils\", \"matplotlib\"])\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import httpx\n",
    "from hypha_rpc import connect_to_server, login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9be5a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Server URL: For this demo we will use the hypha.aicell.io server\n",
    "SERVER_URL = \"https://hypha.aicell.io\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64ee9e3",
   "metadata": {},
   "source": [
    "### Connect to the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da7ff719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please open your browser and login at https://hypha.aicell.io/public/apps/hypha-login/?key=kfVg2CU76xLLBjQL7edrbh\n",
      "Connected to workspace: ws-user-github|49943582\n"
     ]
    }
   ],
   "source": [
    "token = await login({\"server_url\": SERVER_URL})\n",
    "\n",
    "server = await connect_to_server(\n",
    "    {\"server_url\": SERVER_URL, \"token\": token}\n",
    ")\n",
    "workspace = server.config.workspace\n",
    "\n",
    "print(f\"Connected to workspace: {workspace}\")\n",
    "\n",
    "artifact_manager = await server.get_service(\"public/artifact-manager\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6d8045",
   "metadata": {},
   "source": [
    "### Access the BioEngine deployments\n",
    "\n",
    "A public BioEngine instance is available with the service ID `bioimage-io/bioengine-apps`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27092f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "PUBLIC_BIOENGINE = \"bioimage-io/bioengine-apps\"\n",
    "\n",
    "bioengine = await server.get_service(PUBLIC_BIOENGINE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8536abd",
   "metadata": {},
   "source": [
    "### Create the dataset collection (if not already created)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a5ce0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the data collection exists\n",
    "collection_id = f\"{workspace}/bioimageio-colab\"\n",
    "\n",
    "try:\n",
    "    await artifact_manager.list(collection_id)\n",
    "except Exception as e:\n",
    "    expected_error = f'KeyError: \"Artifact with ID \\'{collection_id}\\' does not exist.\"'\n",
    "    if str(e).strip().endswith(expected_error):\n",
    "        print(f\"Collection '{collection_id}' does not exist. Creating it.\")\n",
    "\n",
    "    collection_manifest = {\n",
    "        \"name\": \"BioImage.IO Colab\",\n",
    "        \"description\": \"A collection of annotated images from BioImage.IO Colab.\",\n",
    "    }\n",
    "    collection = await artifact_manager.create(\n",
    "        alias=collection_id,\n",
    "        type=\"collection\",\n",
    "        manifest=collection_manifest,\n",
    "        config={\"permissions\": {\"*\": \"r\", \"@\": \"r+\"}}\n",
    "    )\n",
    "    print(f\"BioImage.IO Colab data collection created with ID: {collection.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413e7668",
   "metadata": {},
   "source": [
    "### Upload the annotated dataset to the collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20a2871f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded manifest.yaml to artifact\n",
      "Uploaded data.zip to artifact\n",
      "Committed artifact with ID: ws-user-github|49943582/hpa-demo\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset content\n",
    "data_path = Path.cwd().parent / \"data\" / \"hpa_demo\" / \"data.zip\"\n",
    "dataset_content = data_path.read_bytes()\n",
    "\n",
    "# Create or update the dataset artifact\n",
    "dataset_manifest = {\n",
    "    \"name\": \"HPA Demo\",\n",
    "    \"description\": \"An annotated dataset for Cellpose finetuning\",\n",
    "    \"type\": \"data\",\n",
    "}\n",
    "data_artifact_alias = \"hpa-demo\"\n",
    "\n",
    "try:\n",
    "    # Edit the existing deployment and stage it for review\n",
    "    artifact = await artifact_manager.edit(\n",
    "        artifact_id=f\"{workspace}/{data_artifact_alias}\",\n",
    "        manifest=dataset_manifest,\n",
    "        type=dataset_manifest[\"type\"],\n",
    "        version=\"stage\",\n",
    "    )\n",
    "except:\n",
    "    # If the artifact does not exist, create it\n",
    "    artifact = await artifact_manager.create(\n",
    "        alias=data_artifact_alias,\n",
    "        parent_id=collection_id,\n",
    "        manifest=dataset_manifest,\n",
    "        type=dataset_manifest[\"type\"],\n",
    "        version=\"stage\",\n",
    "    )\n",
    "    print(f\"Artifact created with ID: {artifact.id}\")\n",
    "\n",
    "# Upload manifest.yaml\n",
    "manifest_url = await artifact_manager.put_file(artifact.id, file_path=\"manifest.yaml\")\n",
    "async with httpx.AsyncClient(timeout=30) as client:\n",
    "    response = await client.put(manifest_url, data=dataset_manifest)\n",
    "    response.raise_for_status()\n",
    "    print(f\"Uploaded manifest.yaml to artifact\")\n",
    "\n",
    "# Upload the dataset content as a zip file\n",
    "data_url = await artifact_manager.put_file(artifact.id, file_path=\"data.zip\")\n",
    "async with httpx.AsyncClient(timeout=30) as client:\n",
    "    response = await client.put(data_url, data=dataset_content)\n",
    "    response.raise_for_status()\n",
    "    print(f\"Uploaded data.zip to artifact\")\n",
    "\n",
    "# Commit the artifact\n",
    "await artifact_manager.commit(\n",
    "    artifact_id=artifact.id,\n",
    "    version=\"new\",\n",
    ")\n",
    "print(f\"Committed artifact with ID: {artifact.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2e9669",
   "metadata": {},
   "source": [
    "### Prepare the data for training\n",
    "\n",
    "Create an artifact for the fine-tuned Cellpose model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d5d252d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_manifest = {\n",
    "    \"name\": \"Finetuned Cellpose model\",\n",
    "    \"description\": \"Finetuned model for Cellpose cyto3\",\n",
    "    \"type\": \"model\",\n",
    "}\n",
    "model_artifact_alias = \"cellpose-cyto3-hpa-finetuned\"\n",
    "\n",
    "try:\n",
    "    model_artifact = await artifact_manager.create(\n",
    "        alias=model_artifact_alias,\n",
    "        parent_id=collection_id,\n",
    "        manifest=model_manifest,\n",
    "        type=model_manifest[\"type\"],\n",
    "        version=\"stage\",\n",
    "    )\n",
    "except:\n",
    "    model_artifact_id = f\"{workspace}/{model_artifact_alias}\"\n",
    "    answer = input(\n",
    "        f\"Artifact {model_artifact_id} already exists. Do you want to overwrite it? (y/n): \"\n",
    "    )\n",
    "    if answer.lower() != \"y\":\n",
    "        raise RuntimeError(\n",
    "            f\"Artifact {model_artifact_id} already exists and will not be overwritten.\"\n",
    "        )\n",
    "\n",
    "    # Overwrite the existing artifact\n",
    "    model_artifact = await artifact_manager.edit(\n",
    "        artifact_id=f\"{workspace}/{model_artifact_alias}\",\n",
    "        manifest=model_manifest,\n",
    "        type=model_manifest[\"type\"],\n",
    "        version=\"stage\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a2b1fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create presigned URLs for data download and model upload\n",
    "data_download_url = await artifact_manager.get_file(\n",
    "    artifact_id=f\"{workspace}/{data_artifact_alias}\", file_path=\"data.zip\"\n",
    ")\n",
    "\n",
    "model_upload_url = await artifact_manager.put_file(\n",
    "    model_artifact.id, file_path=model_artifact_alias.replace(\"-\", \"_\")\n",
    ")\n",
    "\n",
    "data = {\n",
    "    \"data_download_url\": data_download_url,\n",
    "    \"model_upload_url\": model_upload_url,\n",
    "    \"initial_model\": \"cyto3\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294fffda",
   "metadata": {},
   "source": [
    "### Run the Cellpose fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8110789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Committed artifact with ID: ws-user-github|49943582/cellpose-cyto3-hpa-finetuned\n",
      "Average precision at iou threshold 0.5: 0.534\n"
     ]
    }
   ],
   "source": [
    "result = await bioengine.bioimage_io_cellpose_finetuning.train(data=data)\n",
    "await artifact_manager.commit(artifact_id=model_artifact.id)\n",
    "print(f\"Committed artifact with ID: {model_artifact.id}\")\n",
    "\n",
    "print(f\"Average precision at iou threshold 0.5: {result['final_average_precision']['0.5']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0fa39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import httpx\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "# Create a temporary directory to save the downloaded file\n",
    "data_dir = tempfile.mkdtemp()\n",
    "\n",
    "# Define the path to save the downloaded zip file\n",
    "zip_file_path = Path(data_dir) / \"data.zip\"\n",
    "\n",
    "# Download the zip file\n",
    "download_url = await artifact_manager.get_file(\n",
    "    artifact_id=\"hpa-demo\", file_path=\"data.zip\"\n",
    ")\n",
    "\n",
    "async with httpx.AsyncClient(timeout=30) as client:\n",
    "    response = await client.get(download_url)\n",
    "    response.raise_for_status()\n",
    "    with open(zip_file_path, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "# Unzip the downloaded file\n",
    "with zipfile.ZipFile(zip_file_path, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(data_dir)\n",
    "\n",
    "print(f\"Data downloaded and extracted to: {data_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6872ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from cellpose import models, train, io, metrics\n",
    "\n",
    "\n",
    "image_dir = Path(data_dir) / \"hpa_demo\"\n",
    "annotations_dir = image_dir / \"annotations\"\n",
    "\n",
    "# List to hold pairs of image and corresponding annotation masks\n",
    "image_annotation_pairs = []\n",
    "\n",
    "# Get list of all images and annotations\n",
    "annotation_files = list(annotations_dir.glob(\"*.tif\"))\n",
    "\n",
    "# Iterate through each annotation file\n",
    "for annotation_file in annotation_files:\n",
    "    annotation_name = annotation_file.name\n",
    "    image_name = annotation_name.split(\"_mask_\")[0]\n",
    "    image_file = image_dir / f\"{image_name}.tif\"\n",
    "\n",
    "    image_annotation_pairs.append((image_file, annotation_file))\n",
    "\n",
    "\n",
    "# Print the number of annotations\n",
    "print(f\"Number of annotations: {len(image_annotation_pairs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd789a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tifffile import imread\n",
    "\n",
    "\n",
    "assert len(image_annotation_pairs) >= 5\n",
    "\n",
    "\n",
    "# Plot several random annotations\n",
    "choices = np.random.choice(len(image_annotation_pairs), 5, replace=False)\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "for i in range(5):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    img = imread(image_annotation_pairs[choices[i]][0])\n",
    "    plt.imshow(img.transpose(1, 2, 0))\n",
    "    plt.title(f\"{image_annotation_pairs[choices[i]][0].stem}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(2, 5, i + 6)\n",
    "    mask = imread(image_annotation_pairs[choices[i]][1])\n",
    "    plt.imshow(mask)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435ca810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all indices of the list\n",
    "all_indices = np.arange(len(image_annotation_pairs))\n",
    "\n",
    "# Define the split ratio (e.g., 80% train, 20% test)\n",
    "train_ratio = 0.8\n",
    "train_size = int(len(all_indices) * train_ratio)\n",
    "\n",
    "# Randomly shuffle and split indices\n",
    "np.random.shuffle(all_indices)\n",
    "train_indices = all_indices[:train_size]\n",
    "test_indices = all_indices[train_size:]\n",
    "\n",
    "# Create train and test splits\n",
    "train_files = [image_annotation_pairs[i][0] for i in train_indices]\n",
    "train_labels_files = [image_annotation_pairs[i][1] for i in train_indices]\n",
    "test_files = [image_annotation_pairs[i][0] for i in test_indices]\n",
    "test_labels_files = [image_annotation_pairs[i][1] for i in test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931fff2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_model = \"cyto3\"  # [\"cyto\", \"cyto3\", \"nuclei\", \"tissuenet_cp3\", \"livecell_cp3\", \"yeast_PhC_cp3\", \"yeast_BF_cp3\", \"bact_phase_cp3\", \"bact_fluor_cp3\", \"deepbacs_cp3\", \"None\"]\n",
    "output_model_name = \"CP_HPA\"\n",
    "\n",
    "channels_lut = {\n",
    "    \"Grayscale\": 0,\n",
    "    \"Red\": 1,\n",
    "    \"Green\": 2,\n",
    "    \"Blue\": 3,\n",
    "}\n",
    "\n",
    "channels = [\n",
    "    channels_lut[\"Grayscale\"],  # Channel to use for training\n",
    "    channels_lut[\"Grayscale\"],  # Second training channel (if applicable)\n",
    "]\n",
    "\n",
    "n_epochs = 10\n",
    "learning_rate = 0.000001\n",
    "weight_decay = 0.0001\n",
    "\n",
    "save_path = tempfile.mkdtemp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04eef421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start logger (to see training across epochs)\n",
    "logger = io.logger_setup()\n",
    "\n",
    "# DEFINE CELLPOSE MODEL (without size model)\n",
    "model = models.CellposeModel(gpu=True, model_type=initial_model)\n",
    "\n",
    "new_model_path = train.train_seg(\n",
    "    model.net,\n",
    "    train_files=train_files,\n",
    "    train_labels_files=train_labels_files,\n",
    "    test_files=test_files,\n",
    "    test_labels_files=test_labels_files,\n",
    "    channels=channels,\n",
    "    save_path=save_path,\n",
    "    n_epochs=n_epochs,\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    SGD=True,\n",
    "    nimg_per_epoch=1,\n",
    "    model_name=output_model_name,\n",
    "    min_train_masks=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e7fa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model_path[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caf20f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get files (during training, test_data is transformed so we will load it again)\n",
    "test_data = [imread(image_path) for image_path in test_files[:2]]\n",
    "test_labels = [imread(image_path) for image_path in test_labels_files[:2]]\n",
    "\n",
    "# diameter of labels in training images\n",
    "# use model diameter if user diameter is 0\n",
    "diameter = 0\n",
    "diameter = model.diam_labels if diameter == 0 else diameter\n",
    "diam_labels = model.diam_labels.item()\n",
    "\n",
    "# run model on test images\n",
    "masks = model.eval(test_data, channels=channels, diameter=diam_labels)[0]\n",
    "\n",
    "# check performance using ground truth labels\n",
    "ap = metrics.average_precision(test_labels, masks)[0]\n",
    "print(\"\")\n",
    "print(f\">>> average precision at iou threshold 0.5 = {ap[:,0].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f71bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "ap = metrics.average_precision(test_labels, masks, threshold=[0.5, 0.75, 0.9])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f2d109",
   "metadata": {},
   "outputs": [],
   "source": [
    "{t: p for t, p in zip([0.5, 0.75, 0.9], ap.mean(axis=0))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2dd7dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fbef9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38904131",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 6))\n",
    "\n",
    "for i in range(2):  # Two rows\n",
    "    # Plot the image\n",
    "    plt.subplot(2, 3, i * 3 + 1)\n",
    "    plt.imshow(test_data[i].transpose(1, 2, 0))\n",
    "    plt.axis(\"off\")\n",
    "    if i == 0:\n",
    "        plt.title(\"Image\")\n",
    "\n",
    "    # Plot the predicted labels\n",
    "    plt.subplot(2, 3, i * 3 + 2)\n",
    "    plt.imshow(masks[i])\n",
    "    plt.axis(\"off\")\n",
    "    if i == 0:\n",
    "        plt.title(\"Predicted Labels\")\n",
    "\n",
    "    # Plot the true labels\n",
    "    plt.subplot(2, 3, i * 3 + 3)\n",
    "    plt.imshow(test_labels[i])\n",
    "    plt.axis(\"off\")\n",
    "    if i == 0:\n",
    "        plt.title(\"True Labels\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c1770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.remove(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0fa976",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioengine-worker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
